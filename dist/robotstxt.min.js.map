{"version":3,"sources":["robotstxt.js"],"names":["Rule","constructor","type","path","this","Group","userAgent","crawlDelay","undefined","rules","getName","getCrawlDelay","getRules","allow","addRule","disallow","Error","push","RobotsTxtParser","content","parsedData","groups","sitemaps","pathMatchesCache","parse","line","new_content","split","let","processedLine","trim","directive","commentIndex","indexOf","slice","colonIndex","toLowerCase","value","unshift","user_agent_list","same_ua","temp_groups","index","length","current","next","forEach","agent","isNaN","Object","keys","map","key","isAllowed","url","rule","getApplicableRules","urlPath","normalizeUrlPath","matchingRules","pathMatches","mostSpecific","currentSpecificity","getRuleSpecificity","isDisallowed","getSitemaps","getGroup","i","group","specificity","getApplicableGroups","exactGroups","filter","reduce","acc","concat","normalizePath","URL","pathname","error","rulePath","cacheKey","hasOwnProperty","regexPattern","replace","result","RegExp","test","singleSlash","decodeURIComponent","robotstxt","exports","window","define","amd"],"mappings":";CAEC,WAMSA,EAMFC,YAAYC,EAAMC,GAEdC,KAAKF,KAAOA,EAEZE,KAAKD,KAAOA,CAChB,CACJ,OAKME,EAKFJ,YAAYK,GAERF,KAAKE,UAAYA,EAEjBF,KAAKG,WAAaC,KAAAA,EAElBJ,KAAKK,MAAQ,EACjB,CAMAC,UACI,OAAON,KAAKE,SAChB,CAMAK,gBACI,OAAOP,KAAKG,UAChB,CAMAK,WACI,OAAOR,KAAKK,KAChB,CAMAI,MAAMV,GACFC,KAAKU,QAAQ,QAASX,CAAI,CAC9B,CAMAY,SAASZ,GACLC,KAAKU,QAAQ,WAAYX,CAAI,CACjC,CAOAW,QAAQZ,EAAMC,GACV,GAAoB,KAAA,IAATD,EAAsB,MAAM,IAAIc,MAAM,mCAAmC,EACpF,GAAoB,KAAA,IAATb,EAAsB,MAAM,IAAIa,MAAM,mCAAmC,EACpFZ,KAAKK,MAAMQ,KAAK,IAAIjB,EAAKE,EAAMC,CAAI,CAAC,CACxC,CACJ,OAKMe,EAKFjB,YAAYkB,GAORf,KAAKgB,WAAa,CACdC,OAAQ,GACRC,SAAU,EACd,EAMAlB,KAAKmB,iBAAmB,GAExBnB,KAAKoB,MAAML,CAAO,CACtB,CAOAK,MAAML,GACF,GAAuB,KAAA,IAAZA,EAAyB,MAAM,IAAIH,MAAM,sCAAsC,EAE1F,IAGWS,EAHLC,EAAc,GAGpB,IAAWD,KAAQN,EAAQQ,MAAM,YAAY,EAAG,CAC5CC,IAAIC,EAAgBJ,EAAKK,KAAK,EAE9B,IAaMC,EAbAC,EAAeH,EAAcI,QAAQ,GAAG,GAI1CJ,EADiB,CAAC,IAAlBG,EACgBH,EAAcK,MAAM,EAAGF,CAAY,EAAEF,KAAK,EAGzDD,IAIc,CAAC,KAFdM,EAAaN,EAAcI,QAAQ,GAAG,KAItCF,EAAYF,EAAcK,MAAM,EAAGC,CAAU,EAAEL,KAAK,EAAEM,YAAY,EAClEC,EAAQR,EAAcK,MAAMC,EAAa,CAAC,EAAEL,KAAK,EAEnDC,IAAaM,GACbX,EAAYT,KAAK,CAAEc,UAAAA,EAAWM,MAAAA,CAAM,CAAC,CAE7C,CAGIX,EAAY,IAAmC,eAA7BA,EAAY,GAAGK,WACjCL,EAAYY,QAAQ,CAAEP,UAAW,aAAcM,MAAO,GAAI,CAAC,EAG/DT,IAAIW,EAAkB,GAClBC,EAAU,CAAA,EAERC,EAAc,GAGpB,IAAKb,IAAIc,EAAQ,EAAGA,EAAQhB,EAAYiB,OAAQD,CAAK,GAAI,CACrD,IAAME,EAAUlB,EAAYgB,GAC5B,IAAMG,EAAOnB,EAAYgB,EAAQ,GAEjC,GAA0B,eAAtBE,EAAQb,UACRQ,EAAgBtB,KAAK2B,EAAQP,KAAK,EAE7BI,EAAYG,EAAQP,SACrBI,EAAYG,EAAQP,OAAS,IAAIhC,EAAMuC,EAAQP,KAAK,QAGvD,GAA0B,UAAtBO,EAAQb,UACbQ,EAAgBO,QAAQC,GAASN,EAAYM,GAAOlC,MAAM+B,EAAQP,KAAK,CAAC,EACxEG,EAAU,CAAA,OAET,GAA0B,aAAtBI,EAAQb,UACbQ,EAAgBO,QAAQC,GAASN,EAAYM,GAAOhC,SAAS6B,EAAQP,KAAK,CAAC,EAC3EG,EAAU,CAAA,OAET,GAA0B,gBAAtBI,EAAQb,UAA6B,CAC1C,IAAMxB,EAAaqC,CAAAA,EAAQP,MAE3B,GAAI,CAACW,MAAMzC,CAAU,EAAG,CACpB,GAAIA,GAAc,EACd,MAAM,IAAIS,sEAAsET,IAAa,EAGjGgC,EAAgBO,QAAQC,IACfN,EAAYM,GAAOxC,aACpBkC,EAAYM,GAAOxC,WAAaA,EAExC,CAAC,CACL,CACAiC,EAAU,CAAA,CACd,KAC+B,YAAtBI,EAAQb,WACb3B,KAAKgB,WAAWE,SAASL,KAAK2B,EAAQP,KAAK,EAI3CQ,GAAQL,GAA8B,eAAnBK,EAAKd,YACxBS,EAAU,CAAA,EACVD,EAAkB,GAE1B,CAEAnC,KAAKgB,WAAWC,OAAS4B,OAAOC,KAAKT,CAAW,EAAEU,IAAIC,GAAOX,EAAYW,EAAI,CACjF,CAQAC,UAAUC,EAAKhD,GACX,GAAmB,KAAA,IAARgD,EAAqB,MAAM,IAAItC,MAAM,kCAAkC,EAClF,GAAyB,KAAA,IAAdV,EAA2B,MAAM,IAAIU,MAAM,wCAAwC,EAE9F,IAIWuC,EAUAA,EAdL9C,EAAQL,KAAKoD,mBAAmBlD,CAAS,EACzCmD,EAAUrD,KAAKsD,iBAAiBJ,CAAG,EACnCK,EAAgB,GAEtB,IAAWJ,KAAQ9C,EACXL,KAAKwD,YAAYL,EAAKpD,KAAMsD,CAAO,GACnCE,EAAc1C,KAAKsC,CAAI,EAI/B,GAA6B,IAAzBI,EAAchB,OAAc,MAAO,CAAA,EAGvCf,IAAIiC,EAAeF,EAAc,GACjC,IAAWJ,KAAQI,EAAe,CAC9B,IAAMG,EAAqB1D,KAAK2D,mBAAmBR,EAAKpD,IAAI,EAC5BC,KAAK2D,mBAAmBF,EAAa1D,IAAI,EAErE2D,IACAD,EAAeN,EAEvB,CAEA,MAA6B,UAAtBM,EAAa3D,IACxB,CAQA8D,aAAaV,EAAKhD,GACd,MAAO,CAACF,KAAKiD,UAAUC,EAAKhD,CAAS,CACzC,CAMA2D,cACI,OAAO7D,KAAKgB,WAAWE,QAC3B,CAQA4C,SAAS5D,GACL,GAAKA,EACL,IAAKsB,IAAIuC,EAAI,EAAGA,EAAI/D,KAAKgB,WAAWC,OAAOsB,OAAQwB,CAAC,GAAI,CACpD,IAAMC,EAAQhE,KAAKgB,WAAWC,OAAO8C,GAErC,GAAIC,EAAM9D,UAAU8B,YAAY,IAAM9B,EAAU8B,YAAY,EACxD,OAAOgC,CAEf,CAEJ,CAQAL,mBAAmB5D,GACfyB,IAAIyC,EAAclE,EAAKwC,OAGvB,MAF0B,CAAC,IAAvBxC,EAAK8B,QAAQ,GAAG,EAAUoC,GAAe,GACjB,MAAnBlE,EAAK+B,MAAM,CAAC,CAAC,IAAWmC,GAAe,IACzCA,CACX,CAQAC,oBAAoBhE,GAChB,IAAMiE,EAAcnE,KAAKgB,WAAWC,OAAOmD,OAAOJ,GAASA,EAAM1D,QAAQ,EAAE0B,YAAY,IAAM9B,EAAU8B,YAAY,CAAC,EACpH,OAAyB,EAArBmC,EAAY5B,OAAmB4B,EAC5BnE,KAAKgB,WAAWC,OAAOmD,OAAOJ,GAA6B,MAApBA,EAAM1D,QAAQ,CAAS,CACzE,CAQA8C,mBAAmBlD,GAEf,OADcF,KAAKkE,oBAAoBhE,CAAS,EACnCmE,OAAO,CAACC,EAAKN,IAAUM,EAAIC,OAAOP,EAAMxD,SAAS,CAAC,EAAG,EAAE,CACxE,CAQA8C,iBAAiBJ,GACb,IACI,OAAOlD,KAAKwE,cAAc,IAAIC,IAAIvB,CAAG,EAAEwB,QAAQ,CAGnD,CAFE,MAAOC,GACL,OAAO3E,KAAKwE,cAActB,CAAG,CACjC,CACJ,CASAM,YAAYoB,EAAUvB,GAClB,IAAMwB,EAAcD,EAAH,KAAgBvB,EACjC,OAAIrD,KAAKmB,iBAAiB2D,eAAeD,CAAQ,EACtC7E,KAAKmB,iBAAiB0D,IAI7BE,EADmB/E,KAAKwE,cAAcI,CAAQ,EAE7CI,QAAQ,qBAAsB,MAAM,EACpCA,QAAQ,OAAQ,IAAI,EAEnBC,EAAS,IAAIC,OAAO,IAAIH,EAAgB,GAAG,EAAEI,KAAK9B,CAAO,EAC/DrD,KAAKmB,iBAAiB0D,GAAYI,EAEtC,CAQAT,cAAczE,GAEJqF,EADUC,mBAAmBtF,CAAI,EACXiF,QAAQ,QAAS,GAAG,EAChD,MAAuB,MAAnBI,EAAY,GAAmBA,EAC5B,IAAIA,CACf,CACJ,CAOA,SAASE,EAAUvE,GACf,OAAO,IAAID,EAAgBC,CAAO,CACtC,CAIuB,aAAnB,OAAOwE,UACPA,QAAQD,UAAYA,GAEF,aAAlB,OAAOE,SACPA,OAAOF,UAAYA,EACG,YAAlB,OAAOG,SAAyBA,OAAOC,KACvCD,OAAO,KAAM,CAAGH,UAAAA,CAAW,EAAC,CAIxC,GAAE","file":"robotstxt.min.js","sourcesContent":["/* global window, exports, define */\n\n!function () {\n    \"use strict\"\n\n    /**\n     * Single robots.txt rule (allow/disallow directive)\n     */\n    class Rule {\n        /**\n         * Create a new rule instance\n         * @param {string} type - Rule type ('allow' or 'disallow')\n         * @param {string} path - URL path pattern the rule applies to\n         */\n        constructor(type, path) {\n            /** @member {string} */\n            this.type = type\n            /** @member {string} */\n            this.path = path\n        }\n    }\n\n    /**\n     * Group of rules for a specific user agent\n     */\n    class Group {\n        /**\n         * Create a new user agent group\n         * @param {string} userAgent - User agent string this group applies to\n         */\n        constructor(userAgent) {\n            /** @member {string} */\n            this.userAgent = userAgent\n            /** @member {number|undefined} */\n            this.crawlDelay = undefined\n            /** @member {Rule[]} */\n            this.rules = []\n        }\n\n        /**\n         * Get the user agent name for this group\n         * @return {string}\n         */\n        getName() {\n            return this.userAgent\n        }\n\n        /**\n         * Get crawl delay setting for this group\n         * @return {number|undefined}\n         */\n        getCrawlDelay() {\n            return this.crawlDelay\n        }\n\n        /**\n         * Get all rules for this group\n         * @return {Rule[]}\n         */\n        getRules() {\n            return this.rules\n        }\n\n        /**\n         * Add an allow rule to the group\n         * @param {string} path - URL path pattern to allow\n         */\n        allow(path) {\n            this.addRule(\"allow\", path)\n        }\n\n        /**\n         * Add a disallow rule to the group\n         * @param {string} path - URL path pattern to disallow\n         */\n        disallow(path) {\n            this.addRule(\"disallow\", path)\n        }\n\n        /**\n         * Internal method to add a rule\n         * @param {string} type - Rule type ('allow' or 'disallow')\n         * @param {string} path - URL path pattern\n         */\n        addRule(type, path) {\n            if (typeof type === 'undefined') throw new Error(\"The 'type' parameter is required.\")\n            if (typeof path === 'undefined') throw new Error(\"The 'path' parameter is required.\")\n            this.rules.push(new Rule(type, path))\n        }\n    }\n\n    /**\n     * The robots.txt parser class\n     */\n    class RobotsTxtParser {\n        /**\n         * Create a new robots.txt parser\n         * @param {string} content - Raw robots.txt content to parse\n         */\n        constructor(content) {\n            /**\n             * @private\n             * @member {Object}\n             * @property {Group[]} groups - Array of user agent groups/rules\n             * @property {string[]} sitemaps - Array of sitemap URLs found in robots.txt\n             */\n            this.parsedData = {\n                groups: [],\n                sitemaps: []\n            }\n\n            /**\n             * @private\n             * @member {Object}\n             */\n            this.pathMatchesCache = {}\n\n            this.parse(content)\n        }\n\n        /**\n         * Parse raw robots.txt content into structured format\n         * @private\n         * @param {string} content - Raw robots.txt content\n         */\n        parse(content) {\n            if (typeof content === 'undefined') throw new Error(\"The 'content' parameter is required.\")\n\n            const new_content = []\n\n            // Preprocess lines: trim, remove comments, and split directives\n            for (const line of content.split(/\\r\\n|\\r|\\n/)) {\n                let processedLine = line.trim()\n\n                const commentIndex = processedLine.indexOf(\"#\")\n\n                // Remove comments\n                if (commentIndex !== -1) {\n                    processedLine = processedLine.slice(0, commentIndex).trim()\n                }\n\n                if (!processedLine) continue\n\n                const colonIndex = processedLine.indexOf(\":\")\n\n                if (colonIndex === -1) continue\n\n                const directive = processedLine.slice(0, colonIndex).trim().toLowerCase()\n                const value = processedLine.slice(colonIndex + 1).trim()\n\n                if (directive && value) {\n                    new_content.push({ directive, value })\n                }\n            }\n\n            // Handle missing initial User-Agent\n            if (new_content[0] && new_content[0].directive !== \"user-agent\") {\n                new_content.unshift({ directive: \"user-agent\", value: \"*\" })\n            }\n\n            let user_agent_list = []\n            let same_ua = false\n            /** @type {Object.<string, Group>} */\n            const temp_groups = {}\n\n            // Process each directive and build rule groups\n            for (let index = 0; index < new_content.length; index++) {\n                const current = new_content[index]\n                const next = new_content[index + 1]\n\n                if (current.directive === \"user-agent\") {\n                    user_agent_list.push(current.value)\n\n                    if (!temp_groups[current.value]) {\n                        temp_groups[current.value] = new Group(current.value)\n                    }\n                }\n                else if (current.directive === \"allow\") {\n                    user_agent_list.forEach(agent => temp_groups[agent].allow(current.value))\n                    same_ua = true\n                }\n                else if (current.directive === \"disallow\") {\n                    user_agent_list.forEach(agent => temp_groups[agent].disallow(current.value))\n                    same_ua = true\n                }\n                else if (current.directive === \"crawl-delay\") {\n                    const crawlDelay = current.value * 1\n\n                    if (!isNaN(crawlDelay)) {\n                        if (crawlDelay <= 0) {\n                            throw new Error(`Crawl-Delay must be a positive number. The provided value is ${crawlDelay}.`)\n                        }\n\n                        user_agent_list.forEach(agent => {\n                            if (!temp_groups[agent].crawlDelay) {\n                                temp_groups[agent].crawlDelay = crawlDelay\n                            }\n                        })\n                    }\n                    same_ua = true\n                }\n                else if (current.directive === \"sitemap\") {\n                    this.parsedData.sitemaps.push(current.value)\n                }\n\n                // Reset user agent list on new group\n                if (next && same_ua && next.directive === \"user-agent\") {\n                    same_ua = false\n                    user_agent_list = []\n                }\n            }\n\n            this.parsedData.groups = Object.keys(temp_groups).map(key => temp_groups[key])\n        }\n\n        /**\n         * Check if a URL is allowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if allowed, false if disallowed\n         */\n        isAllowed(url, userAgent) {\n            if (typeof url === 'undefined') throw new Error(\"The 'url' parameter is required.\")\n            if (typeof userAgent === 'undefined') throw new Error(\"The 'userAgent' parameter is required.\")\n\n            const rules = this.getApplicableRules(userAgent)\n            const urlPath = this.normalizeUrlPath(url)\n            const matchingRules = []\n\n            for (const rule of rules) {\n                if (this.pathMatches(rule.path, urlPath)) {\n                    matchingRules.push(rule)\n                }\n            }\n\n            if (matchingRules.length === 0) return true\n\n            // Find most specific rule based on path length and special characters\n            let mostSpecific = matchingRules[0]\n            for (const rule of matchingRules) {\n                const currentSpecificity = this.getRuleSpecificity(rule.path)\n                const mostSpecificSpecificity = this.getRuleSpecificity(mostSpecific.path)\n\n                if (currentSpecificity > mostSpecificSpecificity) {\n                    mostSpecific = rule\n                }\n            }\n\n            return mostSpecific.type === \"allow\"\n        }\n\n        /**\n         * Check if a URL is disallowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if disallowed, false if allowed\n         */\n        isDisallowed(url, userAgent) {\n            return !this.isAllowed(url, userAgent)\n        }\n\n        /**\n         * Get sitemap URLs found in robots.txt\n         * @return {string[]} - Array of sitemap URLs\n         */\n        getSitemaps() {\n            return this.parsedData.sitemaps\n        }\n\n        /**\n         * Get group for specific user agent\n         * @private\n         * @param {string} userAgent - User agent to search for\n         * @return {Group|undefined} - Matching group or undefined\n         */\n        getGroup(userAgent) {\n            if (!userAgent) return undefined\n            for (let i = 0; i < this.parsedData.groups.length; i++) {\n                const group = this.parsedData.groups[i]\n\n                if (group.userAgent.toLowerCase() === userAgent.toLowerCase()) {\n                    return group\n                }\n            }\n            return undefined\n        }\n\n        /**\n         * Calculate rule specificity score for path comparison\n         * @private\n         * @param {string} path - URL path pattern\n         * @return {number} - Specificity score (higher = more specific)\n         */\n        getRuleSpecificity(path) {\n            let specificity = path.length\n            if (path.indexOf(\"*\") !== -1) specificity -= 0.5\n            else if (path.slice(-1) === \"$\") specificity += 0.5\n            return specificity\n        }\n\n        /**\n         * Get groups applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Group[]} - Array of matching groups\n         */\n        getApplicableGroups(userAgent) {\n            const exactGroups = this.parsedData.groups.filter(group => group.getName().toLowerCase() === userAgent.toLowerCase())\n            if (exactGroups.length > 0) return exactGroups\n            return this.parsedData.groups.filter(group => group.getName() === \"*\")\n        }\n\n        /**\n         * Get all rules applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Rule[]} - Array of applicable rules\n         */\n        getApplicableRules(userAgent) {\n            const rules = this.getApplicableGroups(userAgent)\n            return rules.reduce((acc, group) => acc.concat(group.getRules()), [])\n        }\n\n        /**\n         * Normalize URL path for comparison\n         * @private\n         * @param {string} url - URL or path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizeUrlPath(url) {\n            try {\n                return this.normalizePath(new URL(url).pathname)\n            } catch (error) {\n                return this.normalizePath(url)\n            }\n        }\n\n        /**\n         * Check if URL path matches rule pattern\n         * @private\n         * @param {string} rulePath - Rule path pattern\n         * @param {string} urlPath - Normalized URL path\n         * @return {boolean} - True if path matches pattern\n         */\n        pathMatches(rulePath, urlPath) {\n            const cacheKey = `${rulePath}__${urlPath}`\n            if (this.pathMatchesCache.hasOwnProperty(cacheKey)) {\n                return this.pathMatchesCache[cacheKey]\n            }\n\n            const normalizedRule = this.normalizePath(rulePath)\n            let regexPattern = normalizedRule\n                .replace(/[.^+?(){}[\\]|\\\\]/gu, \"\\\\$&\")\n                .replace(/\\*/gu, \".*\")\n\n            const result = new RegExp(`^${regexPattern}`, \"u\").test(urlPath)\n            this.pathMatchesCache[cacheKey] = result\n            return result\n        }\n\n        /**\n         * Normalize path string for consistent comparisons\n         * @private\n         * @param {string} path - URL path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizePath(path) {\n            const decoded = decodeURIComponent(path)\n            const singleSlash = decoded.replace(/\\/+/gu, \"/\")\n            if (singleSlash[0] === \"/\") return singleSlash\n            return `/${singleSlash}`\n        }\n    }\n\n    /**\n     * Create a new robots.txt parser instance\n     * @param {string} content - Raw robots.txt content\n     * @return {RobotsTxtParser} - Configured parser instance\n     */\n    function robotstxt(content) {\n        return new RobotsTxtParser(content)\n    }\n\n    // Universal module exports\n    /* eslint-disable quote-props */\n    if (typeof exports !== \"undefined\") {\n        exports.robotstxt = robotstxt\n    }\n    if (typeof window !== \"undefined\") {\n        window.robotstxt = robotstxt\n        if (typeof define === \"function\" && define.amd) {\n            define(() => ({ robotstxt }))\n        }\n    }\n    /* eslint-enable quote-props */\n}()\n"]}