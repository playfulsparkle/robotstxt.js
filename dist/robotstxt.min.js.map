{"version":3,"sources":["robotstxt.js"],"names":["Rule","constructor","type","path","this","Group","userAgent","crawlDelay","undefined","rules","getName","getCrawlDelay","getRules","allow","addRule","disallow","Error","push","RobotsTxtParser","content","parsedData","groups","sitemaps","pathMatchesCache","parse","line","new_content","split","let","processedLine","trim","startsWith","colonIndex","indexOf","directive","slice","toLowerCase","value","commentIndex","search","unshift","user_agent_list","same_ua","temp_groups","index","length","current","next","forEach","agent","isNaN","Object","keys","map","key","isAllowed","url","rule","getApplicableRules","urlPath","normalizeUrlPath","matchingRules","pathMatches","mostSpecific","currentSpecificity","getRuleSpecificity","isDisallowed","getSitemaps","getGroup","i","group","specificity","getApplicableGroups","exactGroups","filter","reduce","acc","concat","normalizePath","URL","pathname","error","rulePath","cacheKey","hasOwnProperty","regexPattern","replace","result","RegExp","test","singleSlash","decodeURIComponent","robotstxt","exports","window","define","amd"],"mappings":";CAEC,WAMSA,EAMFC,YAAYC,EAAMC,GAEdC,KAAKF,KAAOA,EAEZE,KAAKD,KAAOA,CAChB,CACJ,OAKME,EAKFJ,YAAYK,GAERF,KAAKE,UAAYA,EAEjBF,KAAKG,WAAaC,KAAAA,EAElBJ,KAAKK,MAAQ,EACjB,CAMAC,UACI,OAAON,KAAKE,SAChB,CAMAK,gBACI,OAAOP,KAAKG,UAChB,CAMAK,WACI,OAAOR,KAAKK,KAChB,CAMAI,MAAMV,GACFC,KAAKU,QAAQ,QAASX,CAAI,CAC9B,CAMAY,SAASZ,GACLC,KAAKU,QAAQ,WAAYX,CAAI,CACjC,CAOAW,QAAQZ,EAAMC,GACV,GAAoB,KAAA,IAATD,EAAsB,MAAM,IAAIc,MAAM,mCAAmC,EACpF,GAAoB,KAAA,IAATb,EAAsB,MAAM,IAAIa,MAAM,mCAAmC,EACpFZ,KAAKK,MAAMQ,KAAK,IAAIjB,EAAKE,EAAMC,CAAI,CAAC,CACxC,CACJ,OAKMe,EAKFjB,YAAYkB,GAORf,KAAKgB,WAAa,CACdC,OAAQ,GACRC,SAAU,EACd,EAMAlB,KAAKmB,iBAAmB,GAExBnB,KAAKoB,MAAML,CAAO,CACtB,CAOAK,MAAML,GACF,GAAuB,KAAA,IAAZA,EAAyB,MAAM,IAAIH,MAAM,sCAAsC,EAE1F,IAEWS,EAFLC,EAAc,GAEpB,IAAWD,KAAQN,EAAQQ,MAAM,YAAY,EAAG,CAC5CC,IAAIC,EAAgBJ,EAAKK,KAAK,EAE9B,GAAKD,GAAiBA,CAAAA,EAAcE,WAAW,GAAG,EAAlD,CAEA,IAAMC,EAAaH,EAAcI,QAAQ,GAAG,EAE5C,GAAmB,CAAC,IAAhBD,EAAJ,CAEA,IAAME,EAAYL,EAAcM,MAAM,EAAGH,CAAU,EAAEF,KAAK,EAAEM,YAAY,EACxER,IAAIS,EAAQR,EAAcM,MAAMH,EAAa,CAAC,EAAEF,KAAK,EAE/CQ,EAAeD,EAAME,OAAO,WAAW,EAExB,CAAC,IAAlBD,IACAD,EAAQA,EAAMF,MAAM,EAAGG,CAAY,EAAER,KAAK,GAG1CI,GAAaG,GACbX,EAAYT,KAAK,CAAEiB,UAAAA,EAAWG,MAAAA,CAAM,CAAC,CAZlB,CAJ8B,CAkBzD,CAGIX,EAAY,IAAmC,eAA7BA,EAAY,GAAGQ,WACjCR,EAAYc,QAAQ,CAAEN,UAAW,aAAcG,MAAO,GAAI,CAAC,EAG/DT,IAAIa,EAAkB,GAClBC,EAAU,CAAA,EAERC,EAAc,GAGpB,IAAKf,IAAIgB,EAAQ,EAAGA,EAAQlB,EAAYmB,OAAQD,CAAK,GAAI,CACrD,IAAME,EAAUpB,EAAYkB,GAC5B,IAAMG,EAAOrB,EAAYkB,EAAQ,GAEjC,GAA0B,eAAtBE,EAAQZ,UACRO,EAAgBxB,KAAK6B,EAAQT,KAAK,EAE7BM,EAAYG,EAAQT,SACrBM,EAAYG,EAAQT,OAAS,IAAIhC,EAAMyC,EAAQT,KAAK,QAGvD,GAA0B,UAAtBS,EAAQZ,UACbO,EAAgBO,QAAQC,GAASN,EAAYM,GAAOpC,MAAMiC,EAAQT,KAAK,CAAC,EACxEK,EAAU,CAAA,OAET,GAA0B,aAAtBI,EAAQZ,UACbO,EAAgBO,QAAQC,GAASN,EAAYM,GAAOlC,SAAS+B,EAAQT,KAAK,CAAC,EAC3EK,EAAU,CAAA,OAET,GAA0B,gBAAtBI,EAAQZ,UAA6B,CAC1C,IAAM3B,EAAauC,CAAAA,EAAQT,MAE3B,GAAI,CAACa,MAAM3C,CAAU,EAAG,CACpB,GAAIA,GAAc,EACd,MAAM,IAAIS,sEAAsET,IAAa,EAGjGkC,EAAgBO,QAAQC,IACfN,EAAYM,GAAO1C,aACpBoC,EAAYM,GAAO1C,WAAaA,EAExC,CAAC,CACL,CACAmC,EAAU,CAAA,CACd,KAC+B,YAAtBI,EAAQZ,WACb9B,KAAKgB,WAAWE,SAASL,KAAK6B,EAAQT,KAAK,EAI3CU,GAAQL,GAA8B,eAAnBK,EAAKb,YACxBQ,EAAU,CAAA,EACVD,EAAkB,GAE1B,CAEArC,KAAKgB,WAAWC,OAAS8B,OAAOC,KAAKT,CAAW,EAAEU,IAAIC,GAAOX,EAAYW,EAAI,CACjF,CAQAC,UAAUC,EAAKlD,GACX,GAAmB,KAAA,IAARkD,EAAqB,MAAM,IAAIxC,MAAM,kCAAkC,EAClF,GAAyB,KAAA,IAAdV,EAA2B,MAAM,IAAIU,MAAM,wCAAwC,EAE9F,IAIWyC,EAUAA,EAdLhD,EAAQL,KAAKsD,mBAAmBpD,CAAS,EACzCqD,EAAUvD,KAAKwD,iBAAiBJ,CAAG,EACnCK,EAAgB,GAEtB,IAAWJ,KAAQhD,EACXL,KAAK0D,YAAYL,EAAKtD,KAAMwD,CAAO,GACnCE,EAAc5C,KAAKwC,CAAI,EAI/B,GAA6B,IAAzBI,EAAchB,OAAc,MAAO,CAAA,EAGvCjB,IAAImC,EAAeF,EAAc,GACjC,IAAWJ,KAAQI,EAAe,CAC9B,IAAMG,EAAqB5D,KAAK6D,mBAAmBR,EAAKtD,IAAI,EAC5BC,KAAK6D,mBAAmBF,EAAa5D,IAAI,EAErE6D,IACAD,EAAeN,EAEvB,CAEA,MAA6B,UAAtBM,EAAa7D,IACxB,CAQAgE,aAAaV,EAAKlD,GACd,MAAO,CAACF,KAAKmD,UAAUC,EAAKlD,CAAS,CACzC,CAMA6D,cACI,OAAO/D,KAAKgB,WAAWE,QAC3B,CAOA8C,SAAS9D,GACL,GAAKA,EACL,IAAKsB,IAAIyC,EAAI,EAAGA,EAAIjE,KAAKgB,WAAWC,OAAOwB,OAAQwB,CAAC,GAAI,CACpD,IAAMC,EAAQlE,KAAKgB,WAAWC,OAAOgD,GAErC,GAAIC,EAAMhE,UAAU8B,YAAY,IAAM9B,EAAU8B,YAAY,EACxD,OAAOkC,CAEf,CAEJ,CAQAL,mBAAmB9D,GACfyB,IAAI2C,EAAcpE,EAAK0C,OAGvB,MAF0B,CAAC,IAAvB1C,EAAK8B,QAAQ,GAAG,EAAUsC,GAAe,GACjB,MAAnBpE,EAAKgC,MAAM,CAAC,CAAC,IAAWoC,GAAe,IACzCA,CACX,CAQAC,oBAAoBlE,GAChB,IAAMmE,EAAcrE,KAAKgB,WAAWC,OAAOqD,OAAOJ,GAASA,EAAM5D,QAAQ,EAAE0B,YAAY,IAAM9B,EAAU8B,YAAY,CAAC,EACpH,OAAyB,EAArBqC,EAAY5B,OAAmB4B,EAC5BrE,KAAKgB,WAAWC,OAAOqD,OAAOJ,GAA6B,MAApBA,EAAM5D,QAAQ,CAAS,CACzE,CAQAgD,mBAAmBpD,GAEf,OADcF,KAAKoE,oBAAoBlE,CAAS,EACnCqE,OAAO,CAACC,EAAKN,IAAUM,EAAIC,OAAOP,EAAM1D,SAAS,CAAC,EAAG,EAAE,CACxE,CAQAgD,iBAAiBJ,GACb,IACI,OAAOpD,KAAK0E,cAAc,IAAIC,IAAIvB,CAAG,EAAEwB,QAAQ,CAGnD,CAFE,MAAOC,GACL,OAAO7E,KAAK0E,cAActB,CAAG,CACjC,CACJ,CASAM,YAAYoB,EAAUvB,GAClB,IAAMwB,EAAcD,EAAH,KAAgBvB,EACjC,OAAIvD,KAAKmB,iBAAiB6D,eAAeD,CAAQ,EACtC/E,KAAKmB,iBAAiB4D,IAI7BE,EADmBjF,KAAK0E,cAAcI,CAAQ,EAE7CI,QAAQ,qBAAsB,MAAM,EACpCA,QAAQ,OAAQ,IAAI,EAEnBC,EAAS,IAAIC,OAAO,IAAIH,EAAgB,GAAG,EAAEI,KAAK9B,CAAO,EAC/DvD,KAAKmB,iBAAiB4D,GAAYI,EAEtC,CAQAT,cAAc3E,GAEJuF,EADUC,mBAAmBxF,CAAI,EACXmF,QAAQ,QAAS,GAAG,EAChD,MAAuB,MAAnBI,EAAY,GAAmBA,EAC5B,IAAIA,CACf,CACJ,CAOA,SAASE,EAAUzE,GACf,OAAO,IAAID,EAAgBC,CAAO,CACtC,CAIuB,aAAnB,OAAO0E,UACPA,QAAQD,UAAYA,GAEF,aAAlB,OAAOE,SACPA,OAAOF,UAAYA,EACG,YAAlB,OAAOG,SAAyBA,OAAOC,KACvCD,OAAO,KAAM,CAAGH,UAAAA,CAAW,EAAC,CAIxC,GAAE","file":"robotstxt.min.js","sourcesContent":["/* global window, exports, define */\n\n!function () {\n    \"use strict\"\n\n    /**\n     * Single robots.txt rule (allow/disallow directive)\n     */\n    class Rule {\n        /**\n         * Create a new rule instance\n         * @param {string} type - Rule type (\"allow\" or \"disallow\")\n         * @param {string} path - URL path pattern the rule applies to\n         */\n        constructor(type, path) {\n            /** @member {string} */\n            this.type = type\n            /** @member {string} */\n            this.path = path\n        }\n    }\n\n    /**\n     * Group of rules for a specific user agent\n     */\n    class Group {\n        /**\n         * Create a new user agent group\n         * @param {string} userAgent - User agent string this group applies to\n         */\n        constructor(userAgent) {\n            /** @member {string} */\n            this.userAgent = userAgent\n            /** @member {number|undefined} */\n            this.crawlDelay = undefined\n            /** @member {Rule[]} */\n            this.rules = []\n        }\n\n        /**\n         * Get the user agent name for this group\n         * @return {string}\n         */\n        getName() {\n            return this.userAgent\n        }\n\n        /**\n         * Get crawl delay setting for this group\n         * @return {number|undefined}\n         */\n        getCrawlDelay() {\n            return this.crawlDelay\n        }\n\n        /**\n         * Get all rules for this group\n         * @return {Rule[]}\n         */\n        getRules() {\n            return this.rules\n        }\n\n        /**\n         * Add an allow rule to the group\n         * @param {string} path - URL path pattern to allow\n         */\n        allow(path) {\n            this.addRule(\"allow\", path)\n        }\n\n        /**\n         * Add a disallow rule to the group\n         * @param {string} path - URL path pattern to disallow\n         */\n        disallow(path) {\n            this.addRule(\"disallow\", path)\n        }\n\n        /**\n         * Internal method to add a rule\n         * @param {string} type - Rule type (\"allow\" or \"disallow\")\n         * @param {string} path - URL path pattern\n         */\n        addRule(type, path) {\n            if (typeof type === \"undefined\") throw new Error(\"The 'type' parameter is required.\")\n            if (typeof path === \"undefined\") throw new Error(\"The 'path' parameter is required.\")\n            this.rules.push(new Rule(type, path))\n        }\n    }\n\n    /**\n     * The robots.txt parser class\n     */\n    class RobotsTxtParser {\n        /**\n         * Create a new robots.txt parser\n         * @param {string} content - Raw robots.txt content to parse\n         */\n        constructor(content) {\n            /**\n             * @private\n             * @member {Object}\n             * @property {Group[]} groups - Array of user agent groups/rules\n             * @property {string[]} sitemaps - Array of sitemap URLs found in robots.txt\n             */\n            this.parsedData = {\n                groups: [],\n                sitemaps: []\n            }\n\n            /**\n             * @private\n             * @member {Object}\n             */\n            this.pathMatchesCache = {}\n\n            this.parse(content)\n        }\n\n        /**\n         * Parse raw robots.txt content into structured format\n         * @private\n         * @param {string} content - Raw robots.txt content\n         */\n        parse(content) {\n            if (typeof content === \"undefined\") throw new Error(\"The 'content' parameter is required.\")\n\n            const new_content = []\n\n            for (const line of content.split(/\\r\\n|\\r|\\n/)) {\n                let processedLine = line.trim()\n\n                if (!processedLine || processedLine.startsWith('#')) continue\n\n                const colonIndex = processedLine.indexOf(':')\n\n                if (colonIndex === -1) continue\n\n                const directive = processedLine.slice(0, colonIndex).trim().toLowerCase()\n                let value = processedLine.slice(colonIndex + 1).trim()\n\n                const commentIndex = value.search(/(?:\\s|^)#/)\n\n                if (commentIndex !== -1) {\n                    value = value.slice(0, commentIndex).trim()\n                }\n\n                if (directive && value) {\n                    new_content.push({ directive, value })\n                }\n            }\n\n            // Handle missing initial User-Agent\n            if (new_content[0] && new_content[0].directive !== \"user-agent\") {\n                new_content.unshift({ directive: \"user-agent\", value: \"*\" })\n            }\n\n            let user_agent_list = []\n            let same_ua = false\n            /** @type {Object.<string, Group>} */\n            const temp_groups = {}\n\n            // Process each directive and build rule groups\n            for (let index = 0; index < new_content.length; index++) {\n                const current = new_content[index]\n                const next = new_content[index + 1]\n\n                if (current.directive === \"user-agent\") {\n                    user_agent_list.push(current.value)\n\n                    if (!temp_groups[current.value]) {\n                        temp_groups[current.value] = new Group(current.value)\n                    }\n                }\n                else if (current.directive === \"allow\") {\n                    user_agent_list.forEach(agent => temp_groups[agent].allow(current.value))\n                    same_ua = true\n                }\n                else if (current.directive === \"disallow\") {\n                    user_agent_list.forEach(agent => temp_groups[agent].disallow(current.value))\n                    same_ua = true\n                }\n                else if (current.directive === \"crawl-delay\") {\n                    const crawlDelay = current.value * 1\n\n                    if (!isNaN(crawlDelay)) {\n                        if (crawlDelay <= 0) {\n                            throw new Error(`Crawl-Delay must be a positive number. The provided value is ${crawlDelay}.`)\n                        }\n\n                        user_agent_list.forEach(agent => {\n                            if (!temp_groups[agent].crawlDelay) {\n                                temp_groups[agent].crawlDelay = crawlDelay\n                            }\n                        })\n                    }\n                    same_ua = true\n                }\n                else if (current.directive === \"sitemap\") {\n                    this.parsedData.sitemaps.push(current.value)\n                }\n\n                // Reset user agent list on new group\n                if (next && same_ua && next.directive === \"user-agent\") {\n                    same_ua = false\n                    user_agent_list = []\n                }\n            }\n\n            this.parsedData.groups = Object.keys(temp_groups).map(key => temp_groups[key])\n        }\n\n        /**\n         * Check if a URL is allowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if allowed, false if disallowed\n         */\n        isAllowed(url, userAgent) {\n            if (typeof url === \"undefined\") throw new Error(\"The 'url' parameter is required.\")\n            if (typeof userAgent === \"undefined\") throw new Error(\"The 'userAgent' parameter is required.\")\n\n            const rules = this.getApplicableRules(userAgent)\n            const urlPath = this.normalizeUrlPath(url)\n            const matchingRules = []\n\n            for (const rule of rules) {\n                if (this.pathMatches(rule.path, urlPath)) {\n                    matchingRules.push(rule)\n                }\n            }\n\n            if (matchingRules.length === 0) return true\n\n            // Find most specific rule based on path length and special characters\n            let mostSpecific = matchingRules[0]\n            for (const rule of matchingRules) {\n                const currentSpecificity = this.getRuleSpecificity(rule.path)\n                const mostSpecificSpecificity = this.getRuleSpecificity(mostSpecific.path)\n\n                if (currentSpecificity > mostSpecificSpecificity) {\n                    mostSpecific = rule\n                }\n            }\n\n            return mostSpecific.type === \"allow\"\n        }\n\n        /**\n         * Check if a URL is disallowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if disallowed, false if allowed\n         */\n        isDisallowed(url, userAgent) {\n            return !this.isAllowed(url, userAgent)\n        }\n\n        /**\n         * Get sitemap URLs found in robots.txt\n         * @return {string[]} - Array of sitemap URLs\n         */\n        getSitemaps() {\n            return this.parsedData.sitemaps\n        }\n\n        /**\n         * Get group for specific user agent\n         * @param {string} userAgent - User agent to search for\n         * @return {Group|undefined} - Matching group or undefined\n         */\n        getGroup(userAgent) {\n            if (!userAgent) return undefined\n            for (let i = 0; i < this.parsedData.groups.length; i++) {\n                const group = this.parsedData.groups[i]\n\n                if (group.userAgent.toLowerCase() === userAgent.toLowerCase()) {\n                    return group\n                }\n            }\n            return undefined\n        }\n\n        /**\n         * Calculate rule specificity score for path comparison\n         * @private\n         * @param {string} path - URL path pattern\n         * @return {number} - Specificity score (higher = more specific)\n         */\n        getRuleSpecificity(path) {\n            let specificity = path.length\n            if (path.indexOf(\"*\") !== -1) specificity -= 0.5\n            else if (path.slice(-1) === \"$\") specificity += 0.5\n            return specificity\n        }\n\n        /**\n         * Get groups applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Group[]} - Array of matching groups\n         */\n        getApplicableGroups(userAgent) {\n            const exactGroups = this.parsedData.groups.filter(group => group.getName().toLowerCase() === userAgent.toLowerCase())\n            if (exactGroups.length > 0) return exactGroups\n            return this.parsedData.groups.filter(group => group.getName() === \"*\")\n        }\n\n        /**\n         * Get all rules applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Rule[]} - Array of applicable rules\n         */\n        getApplicableRules(userAgent) {\n            const rules = this.getApplicableGroups(userAgent)\n            return rules.reduce((acc, group) => acc.concat(group.getRules()), [])\n        }\n\n        /**\n         * Normalize URL path for comparison\n         * @private\n         * @param {string} url - URL or path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizeUrlPath(url) {\n            try {\n                return this.normalizePath(new URL(url).pathname)\n            } catch (error) {\n                return this.normalizePath(url)\n            }\n        }\n\n        /**\n         * Check if URL path matches rule pattern\n         * @private\n         * @param {string} rulePath - Rule path pattern\n         * @param {string} urlPath - Normalized URL path\n         * @return {boolean} - True if path matches pattern\n         */\n        pathMatches(rulePath, urlPath) {\n            const cacheKey = `${rulePath}__${urlPath}`\n            if (this.pathMatchesCache.hasOwnProperty(cacheKey)) {\n                return this.pathMatchesCache[cacheKey]\n            }\n\n            const normalizedRule = this.normalizePath(rulePath)\n            let regexPattern = normalizedRule\n                .replace(/[.^+?(){}[\\]|\\\\]/gu, \"\\\\$&\")\n                .replace(/\\*/gu, \".*\")\n\n            const result = new RegExp(`^${regexPattern}`, \"u\").test(urlPath)\n            this.pathMatchesCache[cacheKey] = result\n            return result\n        }\n\n        /**\n         * Normalize path string for consistent comparisons\n         * @private\n         * @param {string} path - URL path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizePath(path) {\n            const decoded = decodeURIComponent(path)\n            const singleSlash = decoded.replace(/\\/+/gu, \"/\")\n            if (singleSlash[0] === \"/\") return singleSlash\n            return `/${singleSlash}`\n        }\n    }\n\n    /**\n     * Create a new robots.txt parser instance\n     * @param {string} content - Raw robots.txt content\n     * @return {RobotsTxtParser} - Configured parser instance\n     */\n    function robotstxt(content) {\n        return new RobotsTxtParser(content)\n    }\n\n    // Universal module exports\n    /* eslint-disable quote-props */\n    if (typeof exports !== \"undefined\") {\n        exports.robotstxt = robotstxt\n    }\n    if (typeof window !== \"undefined\") {\n        window.robotstxt = robotstxt\n        if (typeof define === \"function\" && define.amd) {\n            define(() => ({ robotstxt }))\n        }\n    }\n    /* eslint-enable quote-props */\n}()\n"]}