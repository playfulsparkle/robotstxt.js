{"version":3,"sources":["robotstxt.js"],"names":["Rule","constructor","type","path","this","re","specialChars","nonGreedyWildcard","regex","createRegex","match","test","let","pattern","replace","slice","RegExp","error","SyntaxError","message","Group","userAgent","crawlDelay","undefined","cacheDelay","rules","comment","robotVersion","visitTime","requestRates","getName","getComment","getRobotVersion","getVisitTime","getRequestRates","getCacheDelay","getCrawlDelay","getRules","addRule","Error","push","RobotsTxtParser","content","groups","sitemaps","cleanParam","host","reports","requestRate","eol","inlineComment","parse","normalizedContent","contentLines","split","index","length","processedLine","trim","colonIndex","indexOf","directive","toLowerCase","value","commentIndex","search","userAgentList","sameUserAgent","userAgentSeen","tempGroups","uaDirectives","currentLine","needsDefaultUa","uaName","normalizedPath","normalizePath","forEach","agent","isNaN","requestRateMatch","startTime","endTime","isValidTime","visitTimeMatch","nextLine","Object","keys","map","key","getReports","isAllowed","url","rule","getApplicableRules","urlPath","normalizeUrlPath","matchingRules","find","r","mostSpecific","currentSpecificity","getRuleSpecificity","mostSpecificSpecificity","isDisallowed","getSitemaps","getCleanParams","getHost","getGroup","group","specificity","getApplicableGroups","exactGroups","filter","reduce","acc","concat","URL","pathname","decodedPath","decodeURIComponent","time","hours","parseInt","substring","minutes","robotstxt","exports","window","define","amd"],"mappings":";CAEC,WAMSA,EAMFC,YAAYC,EAAMC,GACdC,KAAKC,GAAK,CACNC,aAAc,oBACdC,kBAAmB,KACvB,EAEAH,KAAKF,KAAOA,EAEZE,KAAKD,KAAOA,EAEZC,KAAKI,MAAQJ,KAAKK,YAAYN,CAAI,CACtC,CAOAO,MAAMP,GACF,OAAOC,KAAKI,MAAMG,KAAKR,CAAI,CAC/B,CAQAM,YAAYN,GACRS,IAAIC,EAAUV,EACTW,QAAQV,KAAKC,GAAGC,aAAc,MAAM,EACpCQ,QAAQV,KAAKC,GAAGE,kBAAmB,KAAK,EAGnB,QAAtBM,EAAQE,MAAM,CAAC,CAAC,IAChBF,EAAaA,EAAQE,MAAM,EAAG,CAAC,CAAC,EAAtB,KAGd,IACI,OAAO,IAAIC,OAAO,IAAIH,CAAS,CAGnC,CAFE,MAAOI,GACL,MAAM,IAAIC,qCAAqCf,0BAA6Bc,EAAME,OAAS,CAC/F,CACJ,CACJ,OAKMC,EAKFnB,YAAYoB,GAERjB,KAAKiB,UAAYA,EAEjBjB,KAAKkB,WAAaC,KAAAA,EAElBnB,KAAKoB,WAAaD,KAAAA,EAElBnB,KAAKqB,MAAQ,GAEbrB,KAAKsB,QAAU,GAEftB,KAAKuB,aAAeJ,KAAAA,EAEpBnB,KAAKwB,UAAYL,KAAAA,EAEjBnB,KAAKyB,aAAe,EACxB,CAMAC,UACI,OAAO1B,KAAKiB,SAChB,CAMAU,aACI,OAAO3B,KAAKsB,OAChB,CAMAM,kBACI,OAAO5B,KAAKuB,YAChB,CAMAM,eACI,OAAO7B,KAAKwB,SAChB,CAMAM,kBACI,OAAO9B,KAAKyB,YAChB,CAMAM,gBACI,OAAO/B,KAAKoB,UAChB,CAMAY,gBACI,OAAOhC,KAAKkB,UAChB,CAMAe,WACI,OAAOjC,KAAKqB,KAChB,CAOAa,QAAQpC,EAAMC,GACV,GAAoB,KAAA,IAATD,EAAsB,MAAM,IAAIqC,MAAM,mCAAmC,EACpF,GAAoB,KAAA,IAATpC,EAAsB,MAAM,IAAIoC,MAAM,mCAAmC,EACpFnC,KAAKqB,MAAMe,KAAK,IAAIxC,EAAKE,EAAMC,CAAI,CAAC,CACxC,CACJ,OAKMsC,EAKFxC,YAAYyC,GAORtC,KAAKuC,OAAS,GAQdvC,KAAKwC,SAAW,GAWhBxC,KAAKyC,WAAa,GAUlBzC,KAAK0C,KAAOvB,KAAAA,EAOZnB,KAAK2C,QAAU,GAEf3C,KAAKC,GAAK,CACNsB,aAAc,sBACdqB,YAAa,qCACbpB,UAAW,oBACXqB,IAAK,aACLC,cAAe,WACnB,EAEA9C,KAAK+C,MAAMT,CAAO,CACtB,CAOAS,MAAMT,GACF,GAAuB,KAAA,IAAZA,EAAyB,MAAM,IAAIH,MAAM,sCAAsC,EAG1F,IAAMa,EAAoB,GAEpBC,EAAeX,EAAQY,MAAMlD,KAAKC,GAAG4C,GAAG,EAE9C,IAAKrC,IAAI2C,EAAQ,EAAGA,EAAQF,EAAaG,OAAQD,CAAK,GAAI,CAEtD,IAAME,EAAgBJ,EAAaE,GAAOG,KAAK,EAE/C,GAAKD,GAAsC,MAArBA,EAAc,GAApC,CAGA,IAAME,EAAaF,EAAcG,QAAQ,GAAG,EAE5C,GAAmB,CAAC,IAAhBD,EAAJ,CAGA,IAAME,EAAYJ,EAAc1C,MAAM,EAAG4C,CAAU,EAAED,KAAK,EAAEI,YAAY,EAGxElD,IAAImD,EAAQN,EAAc1C,MAAM4C,EAAa,CAAC,EAAED,KAAK,EAG/CM,EAAeD,EAAME,OAAO7D,KAAKC,GAAG6C,aAAa,EAElC,CAAC,IAAlBc,IAEAD,EAAQA,EAAMhD,MAAM,EAAGiD,CAAY,EAAEN,KAAK,GAI1CG,GAAaE,GACbX,EAAkBZ,KAAK,CAAEe,MAAAA,EAAOM,UAAAA,EAAWE,MAAAA,CAAM,CAAC,CAlBvB,CALyB,CAyB5D,CAGAnD,IAAIsD,EAAgB,GAEhBC,EAAgB,CAAA,EAEhBC,EAAgB,CAAA,EAEdC,EAAa,GAGnB,IAAMC,EAAe,CACjB,QACA,WACA,UACA,UACA,gBACA,eACA,aACA,cACA,eAIJ,IAAK1D,IAAI2C,EAAQ,EAAGA,EAAQH,EAAkBI,OAAQD,CAAK,GAAI,CAE3D,IAAMgB,EAAcnB,EAAkBG,GAGtC,IAAMiB,EAAiE,CAAC,IAAjDF,EAAaV,QAAQW,EAAYV,SAAS,GAAY,CAACO,EAgB9E,GAd8B,eAA1BG,EAAYV,WAA8BW,CAAAA,IAC1CJ,EAAgB,CAAA,EAEVK,EAASD,EAAiB,IAAMD,EAAYR,MAEZ,CAAC,IAAnCG,EAAcN,QAAQa,CAAM,GAC5BP,EAAc1B,KAAKiC,CAAM,EAGxBJ,EAAWI,MACZJ,EAAWI,GAAU,IAAIrD,EAAMqD,CAAM,GAIf,UAA1BF,EAAYV,UAAuB,CACnC,IAAMa,EAAiBtE,KAAKuE,cAAcJ,EAAYR,KAAK,EAE3DG,EAAcU,QAAQC,GAASR,EAAWQ,GAAOvC,QAAQ,QAASoC,CAAc,CAAC,EACjFP,EAAgB,CAAA,CACpB,MACK,GAA8B,aAA1BI,EAAYV,UAA0B,CAC3C,IAAMa,EAAiBtE,KAAKuE,cAAcJ,EAAYR,KAAK,EAE3DG,EAAcU,QAAQC,GAASR,EAAWQ,GAAOvC,QAAQ,WAAYoC,CAAc,CAAC,EACpFP,EAAgB,CAAA,CACpB,MACK,GAA8B,YAA1BI,EAAYV,UAAyB,CAC1C,IAAMa,EAAiBtE,KAAKuE,cAAcJ,EAAYR,KAAK,EAE3DG,EAAcU,QAAQC,GAASR,EAAWQ,GAAOvC,QAAQ,UAAWoC,CAAc,CAAC,EACnFP,EAAgB,CAAA,CACpB,MAEK,GAA8B,gBAA1BI,EAAYV,UAA6B,CAC9C,IAAMrC,EAAa+C,CAAAA,EAAYR,MAE/B,GAAIe,MAAMtD,CAAU,EAAG,CACnBpB,KAAK2C,QAAQP,8CAA8C+B,EAAYR,SAAS,EAChF,QACJ,CAEA,GAAIvC,GAAc,EAAG,CACjBpB,KAAK2C,QAAQP,qEAAqEhB,IAAa,EAC/F,QACJ,CAEA0C,EAAcU,QAAQC,IACbR,EAAWQ,GAAOrD,aACnB6C,EAAWQ,GAAOrD,WAAaA,EAEvC,CAAC,EACD2C,EAAgB,CAAA,CACpB,MAEK,GAA8B,gBAA1BI,EAAYV,UAA6B,CAC9C,IAAMvC,EAAaiD,CAAAA,EAAYR,MAE/B,GAAIe,MAAMxD,CAAU,EAAG,CACnBlB,KAAK2C,QAAQP,8CAA8C+B,EAAYR,SAAS,EAChF,QACJ,CAEA,GAAIzC,GAAc,EAAG,CACjBlB,KAAK2C,QAAQP,qEAAqElB,IAAa,EAC/F,QACJ,CAEA4C,EAAcU,QAAQC,IACbR,EAAWQ,GAAOvD,aACnB+C,EAAWQ,GAAOvD,WAAaA,EAEvC,CAAC,EACD6C,EAAgB,CAAA,CACpB,MAEK,GAA8B,YAA1BI,EAAYV,UACjBK,EAAcU,QAAQC,GAASR,EAAWQ,GAAOnD,QAAQc,KAAK+B,EAAYR,KAAK,CAAC,EAChFI,EAAgB,CAAA,OAGf,GAA8B,kBAA1BI,EAAYV,UAA+B,CAChD,GAAI,CAACzD,KAAKC,GAAGsB,aAAahB,KAAK4D,EAAYR,KAAK,EAAG,CAC/C3D,KAAK2C,QAAQP,gDAAgD+B,EAAYR,SAAS,EAClF,QACJ,CAEAG,EAAcU,QAAQC,GAASR,EAAWQ,GAAOlD,aAAe4C,EAAYR,KAAK,EACjFI,EAAgB,CAAA,CACpB,MAGK,GAA8B,iBAA1BI,EAAYV,UAA8B,CACzCkB,EAAmBR,EAAYR,MAAMrD,MAAMN,KAAKC,GAAG2C,WAAW,EACpE,GAAI,CAAC+B,EAAkB,CACnB3E,KAAK2C,QAAQP,+CAA+C+B,EAAYR,SAAS,EACjF,QACJ,CAEA,GAAIgB,EAAiB,IAAMA,EAAiB,GAAI,CAC5C,IAAMC,EAAYD,EAAiB,GAC7BE,EAAUF,EAAiB,GAEjC,GAAI,CAAC3E,KAAK8E,YAAYF,CAAS,GAAK,CAAC5E,KAAK8E,YAAYD,CAAO,EAAG,CAC5D7E,KAAK2C,QAAQP,+DAA+DwC,KAAaC,KAAW,EACpG,QACJ,CACJ,CAEAf,EAAcU,QAAQC,GAASR,EAAWQ,GAAOhD,aAAaW,KAAK+B,EAAYR,KAAK,CAAC,EACrFI,EAAgB,CAAA,CACpB,MAEK,GAA8B,eAA1BI,EAAYV,UAA4B,CACvCsB,EAAiBZ,EAAYR,MAAMrD,MAAMN,KAAKC,GAAGuB,SAAS,EAChE,GAAI,CAACuD,EAAgB,CACjB/E,KAAK2C,QAAQP,6CAA6C+B,EAAYR,SAAS,EAC/E,QACJ,CAEA,GAAIoB,EAAe,IAAMA,EAAe,GAAI,CACxC,IAAMH,EAAYG,EAAe,GAC3BF,EAAUE,EAAe,GAE/B,GAAI,CAAC/E,KAAK8E,YAAYF,CAAS,GAAK,CAAC5E,KAAK8E,YAAYD,CAAO,EAAG,CAC5D7E,KAAK2C,QAAQP,6DAA6DwC,KAAaC,KAAW,EAClG,QACJ,CACJ,CAEAf,EAAcU,QAAQC,GAASR,EAAWQ,GAAOjD,UAAY2C,EAAYR,KAAK,EAC9EI,EAAgB,CAAA,CACpB,KACmC,YAA1BI,EAAYV,UACjBzD,KAAKwC,SAASJ,KAAK+B,EAAYR,KAAK,EAGL,gBAA1BQ,EAAYV,UACjBzD,KAAKyC,WAAWL,KAAK+B,EAAYR,KAAK,EAEP,SAA1BQ,EAAYV,YACjBzD,KAAK0C,KAAOyB,EAAYR,OAItBqB,EAAWhC,EAAkBG,EAAQ,GAGvC6B,GAAYjB,GAAwC,eAAvBiB,EAASvB,YACtCM,EAAgB,CAAA,EAChBD,EAAgB,GAExB,CAEA9D,KAAKuC,OAAS0C,OAAOC,KAAKjB,CAAU,EAAEkB,IAAIC,GAAOnB,EAAWmB,EAAI,CACpE,CAMAC,aACI,OAAOrF,KAAK2C,OAChB,CAQA2C,UAAUC,EAAKtE,GACX,GAAmB,KAAA,IAARsE,EAAqB,MAAM,IAAIpD,MAAM,kCAAkC,EAClF,GAAyB,KAAA,IAAdlB,EAA2B,MAAM,IAAIkB,MAAM,wCAAwC,EAG9F,IAQWqD,EAiBAA,EAzBLnE,EAAQrB,KAAKyF,mBAAmBxE,CAAS,EAGzCyE,EAAU1F,KAAK2F,iBAAiBJ,CAAG,EAGnCK,EAAgB,GAEtB,IAAWJ,KAAQnE,EACXmE,EAAKlF,MAAMoF,CAAO,GAClBE,EAAcxD,KAAKoD,CAAI,EAI/B,GAA6B,IAAzBI,EAAcxC,OAAc,MAAO,CAAA,EAIvC,GAD0B/B,EAAMwE,KAAKC,GAAgB,aAAXA,EAAEhG,MAAkC,KAAXgG,EAAE/F,IAAW,EAG5E,MAAO,CAAA,EAIXS,IAAIuF,EAAeH,EAAc,GACjC,IAAWJ,KAAQI,EAAe,CAC9B,IAAMI,EAAqBhG,KAAKiG,mBAAmBT,EAAKzF,IAAI,EACtDmG,EAA0BlG,KAAKiG,mBAAmBF,EAAahG,IAAI,GAEhDmG,EAArBF,GAIKA,IAAuBE,GACd,UAAdV,EAAK1F,MAA0C,aAAtBiG,EAAajG,QAEtCiG,EAAeP,EAEvB,CAEA,MAA6B,UAAtBO,EAAajG,IACxB,CAQAqG,aAAaZ,EAAKtE,GACd,MAAO,CAACjB,KAAKsF,UAAUC,EAAKtE,CAAS,CACzC,CAMAmF,cACI,OAAOpG,KAAKwC,QAChB,CAQA6D,iBACI,OAAOrG,KAAKyC,UAChB,CASA6D,UACI,OAAOtG,KAAK0C,IAChB,CAOA6D,SAAStF,GACL,GAAKA,EAEL,IAAKT,IAAI2C,EAAQ,EAAGA,EAAQnD,KAAKuC,OAAOa,OAAQD,CAAK,GAAI,CACrD,IAAMqD,EAAQxG,KAAKuC,OAAOY,GAE1B,GAAIqD,EAAMvF,UAAUyC,YAAY,IAAMzC,EAAUyC,YAAY,EACxD,OAAO8C,CAEf,CAGJ,CAQAP,mBAAmBlG,GAEfS,IAAIiG,EAAc1G,EAAKqD,OAGvB,MAF0B,CAAC,IAAvBrD,EAAKyD,QAAQ,GAAG,EAAUiD,GAAe,GACjB,MAAnB1G,EAAKY,MAAM,CAAC,CAAC,IAAW8F,GAAe,IACzCA,CACX,CAQAC,oBAAoBzF,GAEhB,IAAM0F,EAAc3G,KAAKuC,OAAOqE,OAAOJ,GAASA,EAAM9E,QAAQ,EAAEgC,YAAY,IAAMzC,EAAUyC,YAAY,CAAC,EACzG,OAAyB,EAArBiD,EAAYvD,OAAmBuD,EAC5B3G,KAAKuC,OAAOqE,OAAOJ,GAA6B,MAApBA,EAAM9E,QAAQ,CAAS,CAC9D,CAQA+D,mBAAmBxE,GAGf,OADcjB,KAAK0G,oBAAoBzF,CAAS,EACnC4F,OAAO,CAACC,EAAKN,IAAUM,EAAIC,OAAOP,EAAMvE,SAAS,CAAC,EAAG,EAAE,CACxE,CAQA0D,iBAAiBJ,GACb,IACI,OAAOvF,KAAKuE,cAAc,IAAIyC,IAAIzB,CAAG,EAAE0B,QAAQ,CAGnD,CAFE,MAAOpG,GACL,OAAOb,KAAKuE,cAAcgB,CAAG,CACjC,CACJ,CAQAhB,cAAcxE,GAEVS,IAAI0G,EAEJ,IACIA,EAAcC,mBAAmBpH,CAAI,CAGzC,CAFE,MAAOc,GACLqG,EAAcnH,CAClB,CAIA,OAAImH,GAAkC,MAAnBA,EAAY,GAAmB,IAAIA,EAE/CA,CACX,CAEApC,YAAYsC,GACR,IAAMC,EAAQC,SAASF,EAAKG,UAAU,EAAG,CAAC,EAAG,EAAE,EACzCC,EAAUF,SAASF,EAAKG,UAAU,EAAG,CAAC,EAAG,EAAE,EAGjD,OAAgB,GAATF,GAAcA,GAAS,IAAiB,GAAXG,GAAgBA,GAAW,EACnE,CACJ,CAOA,SAASC,EAAUnF,GACf,OAAO,IAAID,EAAgBC,CAAO,CACtC,CAIuB,aAAnB,OAAOoF,UACPA,QAAQD,UAAYA,GAEF,aAAlB,OAAOE,SACPA,OAAOF,UAAYA,EACG,YAAlB,OAAOG,SAAyBA,OAAOC,KACvCD,OAAO,KAAM,CAAGH,UAAAA,CAAW,EAAC,CAIxC,GAAE","file":"robotstxt.min.js","sourcesContent":["/* global window, exports, define */\n\n!function () {\n    'use strict';\n\n    /**\n     * Single robots.txt rule (allow/disallow directive)\n     */\n    class Rule {\n        /**\n         * Create a new rule instance\n         * @param {string} type - Rule type ('allow', 'disallow' or 'noindex')\n         * @param {string} path - URL path pattern the rule applies to\n         */\n        constructor(type, path) {\n            this.re = {\n                specialChars: /[.^+?(){}[\\]|\\\\]/g, // Escapes special chars\n                nonGreedyWildcard: /\\*/g           // Replaces * with .*?\n            };\n            /** @member {string} */\n            this.type = type;\n            /** @member {string} */\n            this.path = path;\n            /** @member {string} */\n            this.regex = this.createRegex(path);\n        }\n\n        /**\n         * Test if a normalized URL path matches this rule's pattern\n         * @param {string} path - Normalized URL path to test against\n         * @return {boolean} - True if the path matches the rule's pattern\n         */\n        match(path) {\n            return this.regex.test(path);\n        }\n\n        /**\n         * Convert robots.txt path pattern to regular expression\n         * @private\n         * @param {string} path - Normalized URL path pattern to convert\n         * @return {RegExp} - Regular expression for path matching\n         */\n        createRegex(path) {\n            let pattern = path\n                .replace(this.re.specialChars, '\\\\$&')\n                .replace(this.re.nonGreedyWildcard, '.*?');\n\n            // Handle end-of-string matching if $ is at the end\n            if (pattern.slice(-1) === '\\\\$') {\n                pattern = `${pattern.slice(0, -2)}$`;\n            }\n\n            try {\n                return new RegExp(`^${pattern}`);\n            } catch (error) {\n                throw new SyntaxError(`Invalid path pattern \"${path}\" for regex creation: ${error.message}`);\n            }\n        }\n    }\n\n    /**\n     * Group of rules for a specific user agent\n     */\n    class Group {\n        /**\n         * Create a new user agent group\n         * @param {string} userAgent - User agent string this group applies to\n         */\n        constructor(userAgent) {\n            /** @member {string} - User agent identifier for this group */\n            this.userAgent = userAgent;\n            /** @member {number|undefined} - Delay between crawler requests in seconds */\n            this.crawlDelay = undefined;\n            /** @member {number|undefined} - Specifies the minimum interval for a robot to wait after caching one page, before starting to cache another in seconds */\n            this.cacheDelay = undefined;\n            /** @member {Rule[]} - Collection of rules for this user agent */\n            this.rules = [];\n            /** @member {string} - Optional comment associated with the group */\n            this.comment = [];\n            /** @member {string|undefined} - Version of robots.txt specification used */\n            this.robotVersion = undefined;\n            /** @member {string|undefined} - Recommended visit time from robots.txt */\n            this.visitTime = undefined;\n            /** @member {string[]} - Request rate limits for this user agent */\n            this.requestRates = [];\n        }\n\n        /**\n         * Get the user agent name for this group\n         * @return {string} User agent identifier\n         */\n        getName() {\n            return this.userAgent;\n        }\n\n        /**\n         * Get the comment associated with this group\n         * @return {string[]} Group comment if available\n         */\n        getComment() {\n            return this.comment;\n        }\n\n        /**\n         * Get the robots.txt specification version\n         * @return {string|undefined} Version number of robots.txt specification\n         */\n        getRobotVersion() {\n            return this.robotVersion;\n        }\n\n        /**\n         * Get the recommended visit time for crawler\n         * @return {string|undefined} Suggested crawl time window\n         */\n        getVisitTime() {\n            return this.visitTime;\n        }\n\n        /**\n         * Get request rate limitations for this group\n         * @return {string[]} Array of request rate rules\n         */\n        getRequestRates() {\n            return this.requestRates;\n        }\n\n        /**\n         * Get crawl delay setting for this group\n         * @return {number|undefined} Delay between requests in seconds\n         */\n        getCacheDelay() {\n            return this.cacheDelay;\n        }\n\n        /**\n         * Get crawl delay setting for this group\n         * @return {number|undefined} Delay between requests in seconds\n         */\n        getCrawlDelay() {\n            return this.crawlDelay;\n        }\n\n        /**\n         * Get all rules for this group\n         * @return {Rule[]} Array of rule objects\n         */\n        getRules() {\n            return this.rules;\n        }\n\n        /**\n         * Internal method to add a rule\n         * @param {string} type - Rule type ('allow', 'disallow', 'noindex')\n         * @param {string} path - URL path pattern\n         */\n        addRule(type, path) {\n            if (typeof type === 'undefined') throw new Error('The \"type\" parameter is required.');\n            if (typeof path === 'undefined') throw new Error('The \"path\" parameter is required.');\n            this.rules.push(new Rule(type, path));\n        }\n    }\n\n    /**\n     * The robots.txt parser class\n     */\n    class RobotsTxtParser {\n        /**\n         * Create a new robots.txt parser\n         * @param {string} content - Raw robots.txt content to parse\n         */\n        constructor(content) {\n            /**\n             * @private\n             * @type {Group[]}\n             * @description Collection of user agent groups containing access rules.\n             *              Represents all parsed User-agent sections from robots.txt\n             */\n            this.groups = [];\n\n            /**\n             * @private\n             * @type {string[]}\n             * @description Array of absolute URLs to sitemaps specified in robots.txt.\n             *              Collected from Sitemap directives across the entire file.\n             */\n            this.sitemaps = [];\n\n            /**\n             * @private\n             * @type {string[]}\n             * @description Collection of Clean-param directive values specifying\n             *              dynamic parameters that should be ignored during URL\n             *              canonicalization. These typically include tracking\n             *              parameters, session IDs, or other URL-specific values\n             *              that don't affect content.\n             */\n            this.cleanParam = [];\n\n            /**\n             * @private\n             * @type {string|undefined}\n             * @description Preferred canonical host declaration from Host directive, used to:\n             *                - Specify the primary domain when multiple mirrors exist\n             *                - Handle internationalization/country targeting (ccTLDs)\n             *                - Enforce consistent domain (with/without www) for search engines\n             */\n            this.host = undefined;\n\n            /**\n             * @private\n             * @type {string[]}\n             * @description Parsing error, warning etc. reports\n             */\n            this.reports = [];\n\n            this.re = {\n                robotVersion: /^(\\d+)(?:\\.(\\d+))*$/,\n                requestRate: /^\\d+\\/\\d+[smh]?\\s+(\\d{4})-(\\d{4})$/,\n                visitTime: /^(\\d{4})-(\\d{4})$/,\n                eol: /\\r\\n|\\r|\\n/,\n                inlineComment: /(?:\\s|^)#/\n            };\n\n            this.parse(content);\n        }\n\n        /**\n         * Parse raw robots.txt content into structured format\n         * @private\n         * @param {string} content - Raw robots.txt content\n         */\n        parse(content) {\n            if (typeof content === 'undefined') throw new Error('The \"content\" parameter is required.');\n\n            /** @type {string[]} */\n            const normalizedContent = [];\n\n            const contentLines = content.split(this.re.eol);\n\n            for (let index = 0; index < contentLines.length; index++) {\n                /** @type {string}  - Trimed robots.txt line */\n                const processedLine = contentLines[index].trim();\n\n                if (!processedLine || processedLine[0] === '#') continue;\n\n                /** @type {number} - directive:value separated using colon character */\n                const colonIndex = processedLine.indexOf(':');\n\n                if (colonIndex === -1) continue;\n\n                /** @type {string} - trimmed, lowercase directive */\n                const directive = processedLine.slice(0, colonIndex).trim().toLowerCase();\n\n                /** @type {string} - trimmed directive value */\n                let value = processedLine.slice(colonIndex + 1).trim();\n\n                /** @type {number} - directive value comment index */\n                const commentIndex = value.search(this.re.inlineComment);\n\n                if (commentIndex !== -1) {\n                    // Remove inline comment\n                    value = value.slice(0, commentIndex).trim();\n                }\n\n                // Make sure that directive and value is set\n                if (directive && value) {\n                    normalizedContent.push({ index, directive, value });\n                }\n            }\n\n            /** @type {string[]} */\n            let userAgentList = [];\n            /** @type {boolean} */\n            let sameUserAgent = false;\n            /** @type {boolean} */\n            let userAgentSeen = false;\n            /** @type {Object.<string, Group>} */\n            const tempGroups = {};\n\n            /** @type {string} - Array of directives which require at least one User-Agent present. */\n            const uaDirectives = [\n                'allow',\n                'disallow',\n                'noindex',\n                'comment',\n                'robot-version',\n                'request-rate',\n                'visit-time',\n                'cache-delay',\n                'crawl-delay'\n            ];\n\n            // Process each directive and build rule groups\n            for (let index = 0; index < normalizedContent.length; index++) {\n                /** @type {Object.<string, string>} */\n                const currentLine = normalizedContent[index];\n\n                /** @type {boolean} */\n                const needsDefaultUa = uaDirectives.indexOf(currentLine.directive) !== -1 && !userAgentSeen;\n\n                if (currentLine.directive === 'user-agent' || needsDefaultUa) {\n                    userAgentSeen = true;\n\n                    const uaName = needsDefaultUa ? '*' : currentLine.value;\n\n                    if (userAgentList.indexOf(uaName) === -1) {\n                        userAgentList.push(uaName);\n                    }\n\n                    if (!tempGroups[uaName]) {\n                        tempGroups[uaName] = new Group(uaName);\n                    }\n                }\n\n                if (currentLine.directive === 'allow') {\n                    const normalizedPath = this.normalizePath(currentLine.value);\n\n                    userAgentList.forEach(agent => tempGroups[agent].addRule('allow', normalizedPath));\n                    sameUserAgent = true;\n                }\n                else if (currentLine.directive === 'disallow') {\n                    const normalizedPath = this.normalizePath(currentLine.value);\n\n                    userAgentList.forEach(agent => tempGroups[agent].addRule('disallow', normalizedPath));\n                    sameUserAgent = true;\n                }\n                else if (currentLine.directive === 'noindex') {\n                    const normalizedPath = this.normalizePath(currentLine.value);\n\n                    userAgentList.forEach(agent => tempGroups[agent].addRule('noindex', normalizedPath));\n                    sameUserAgent = true;\n                }\n                // Cache-delay: 10\n                else if (currentLine.directive === 'cache-delay') {\n                    const cacheDelay = currentLine.value * 1;\n\n                    if (isNaN(cacheDelay)) {\n                        this.reports.push(`Invalid Cache-delay directive value: \"${currentLine.value}\".`);\n                        continue;\n                    }\n\n                    if (cacheDelay <= 0) {\n                        this.reports.push(`Cache-delay must be a positive number. The provided value is ${cacheDelay}.`);\n                        continue;\n                    }\n\n                    userAgentList.forEach(agent => {\n                        if (!tempGroups[agent].cacheDelay) {\n                            tempGroups[agent].cacheDelay = cacheDelay;\n                        }\n                    });\n                    sameUserAgent = true;\n                }\n                // Crawl-delay: 10\n                else if (currentLine.directive === 'crawl-delay') {\n                    const crawlDelay = currentLine.value * 1;\n\n                    if (isNaN(crawlDelay)) {\n                        this.reports.push(`Invalid Crawl-Delay directive value: \"${currentLine.value}\".`);\n                        continue;\n                    }\n\n                    if (crawlDelay <= 0) {\n                        this.reports.push(`Crawl-Delay must be a positive number. The provided value is ${crawlDelay}.`);\n                        continue;\n                    }\n\n                    userAgentList.forEach(agent => {\n                        if (!tempGroups[agent].crawlDelay) {\n                            tempGroups[agent].crawlDelay = crawlDelay;\n                        }\n                    });\n                    sameUserAgent = true;\n                }\n                // Comment: [text]\n                else if (currentLine.directive === 'comment') {\n                    userAgentList.forEach(agent => tempGroups[agent].comment.push(currentLine.value));\n                    sameUserAgent = true;\n                }\n                // Robot-version: 2.0.0\n                else if (currentLine.directive === 'robot-version') {\n                    if (!this.re.robotVersion.test(currentLine.value)) {\n                        this.reports.push(`Invalid Robot-Version directive value: \"${currentLine.value}\".`);\n                        continue;\n                    }\n\n                    userAgentList.forEach(agent => tempGroups[agent].robotVersion = currentLine.value);\n                    sameUserAgent = true;\n                }\n                // Request-rate: <rate> # 100/24h\n                // Request-rate: <rate> <time> '-' <time> # 100/24h 1300-1659\n                else if (currentLine.directive === 'request-rate') {\n                    const requestRateMatch = currentLine.value.match(this.re.requestRate);\n                    if (!requestRateMatch) {\n                        this.reports.push(`Invalid Request-rate directive value: \"${currentLine.value}\".`);\n                        continue;\n                    }\n\n                    if (requestRateMatch[1] && requestRateMatch[2]) {\n                        const startTime = requestRateMatch[1];\n                        const endTime = requestRateMatch[2];\n\n                        if (!this.isValidTime(startTime) || !this.isValidTime(endTime)) {\n                            this.reports.push(`Invalid Request-rate directive start-end time format: \"${startTime}-${endTime}\".`);\n                            continue;\n                        }\n                    }\n\n                    userAgentList.forEach(agent => tempGroups[agent].requestRates.push(currentLine.value));\n                    sameUserAgent = true;\n                }\n                // Visit-time: <time> '-' <time>\n                else if (currentLine.directive === 'visit-time') {\n                    const visitTimeMatch = currentLine.value.match(this.re.visitTime);\n                    if (!visitTimeMatch) {\n                        this.reports.push(`Invalid Visit-time directive value: \"${currentLine.value}\".`);\n                        continue;\n                    }\n\n                    if (visitTimeMatch[1] && visitTimeMatch[2]) {\n                        const startTime = visitTimeMatch[1];\n                        const endTime = visitTimeMatch[2];\n\n                        if (!this.isValidTime(startTime) || !this.isValidTime(endTime)) {\n                            this.reports.push(`Invalid Visit-time directive start-end time format: \"${startTime}-${endTime}\".`);\n                            continue;\n                        }\n                    }\n\n                    userAgentList.forEach(agent => tempGroups[agent].visitTime = currentLine.value);\n                    sameUserAgent = true;\n                }\n                else if (currentLine.directive === 'sitemap') {\n                    this.sitemaps.push(currentLine.value);\n                }\n                // Clean-param: [parameter1]&[parameter2]&[...] [path]\n                else if (currentLine.directive === 'clean-param') {\n                    this.cleanParam.push(currentLine.value);\n                }\n                else if (currentLine.directive === 'host') {\n                    this.host = currentLine.value;\n                }\n\n                /** @type {Object.<string, string>} */\n                const nextLine = normalizedContent[index + 1];\n\n                // Reset user agent list on new group\n                if (nextLine && sameUserAgent && nextLine.directive === 'user-agent') {\n                    sameUserAgent = false;\n                    userAgentList = [];\n                }\n            }\n\n            this.groups = Object.keys(tempGroups).map(key => tempGroups[key]);\n        }\n\n        /**\n         * Returns the reports collected during parsing and validating the robots.txt file\n         * @returns {string[]} Parsing error, warning etc. reports\n         */\n        getReports() {\n            return this.reports;\n        }\n\n        /**\n         * Check if a URL is allowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if allowed, false if disallowed\n         */\n        isAllowed(url, userAgent) {\n            if (typeof url === 'undefined') throw new Error('The \"url\" parameter is required.');\n            if (typeof userAgent === 'undefined') throw new Error('The \"userAgent\" parameter is required.');\n\n            /** @type {Rule[]} */\n            const rules = this.getApplicableRules(userAgent);\n\n            /** @type {string} */\n            const urlPath = this.normalizeUrlPath(url);\n\n            /** @type {Rule[]} */\n            const matchingRules = [];\n\n            for (const rule of rules) {\n                if (rule.match(urlPath)) {\n                    matchingRules.push(rule);\n                }\n            }\n\n            if (matchingRules.length === 0) return true;\n\n            // Special case for empty Disallow rule\n            const emptyDisallowRule = rules.find(r => r.type === 'disallow' && r.path === '');\n            if (emptyDisallowRule) {\n                // Empty Disallow means \"allow all\"\n                return true;\n            }\n\n            // Find most specific rule\n            let mostSpecific = matchingRules[0];\n            for (const rule of matchingRules) {\n                const currentSpecificity = this.getRuleSpecificity(rule.path);\n                const mostSpecificSpecificity = this.getRuleSpecificity(mostSpecific.path);\n\n                if (currentSpecificity > mostSpecificSpecificity) {\n                    mostSpecific = rule;\n                }\n                // If equal specificity but this is an Allow (and current most specific is Disallow)\n                else if (currentSpecificity === mostSpecificSpecificity &&\n                    rule.type === 'allow' && mostSpecific.type === 'disallow') {\n                    // Prefer Allow rule (least restrictive) in case of equal specificity\n                    mostSpecific = rule;\n                }\n            }\n\n            return mostSpecific.type === 'allow';\n        }\n\n        /**\n         * Check if a URL is disallowed for specified user agent\n         * @param {string} url - URL to check\n         * @param {string} userAgent - User agent to check rules for\n         * @return {boolean} - True if disallowed, false if allowed\n         */\n        isDisallowed(url, userAgent) {\n            return !this.isAllowed(url, userAgent);\n        }\n\n        /**\n         * Get sitemap URLs found in robots.txt\n         * @return {string[]} - Array of sitemap URLs\n         */\n        getSitemaps() {\n            return this.sitemaps;\n        }\n\n        /**\n         * Retrieve Clean-param directives for URL parameter sanitization\n         * @returns {string[]} Array of parameter patterns in Clean-param format:\n         *                         - Each entry follows \"param[&param2] [path-prefix]\" syntax\n         *                         - Path prefix is optional and specifies URL scope\n         */\n        getCleanParams() {\n            return this.cleanParam;\n        }\n\n        /**\n         * Get canonical host declaration for domain normalization\n         * @returns {string|undefined} Preferred hostname in one of these formats:\n         *                        - Domain without protocol (e.g., \"www.example.com\")\n         *                        - Domain with port (e.g., \"example.com:8080\")\n         *                        - undefined if no Host directive declared\n         */\n        getHost() {\n            return this.host;\n        }\n\n        /**\n         * Get group for specific user agent\n         * @param {string} userAgent - User agent to search for\n         * @return {Group|undefined} - Matching group or undefined\n         */\n        getGroup(userAgent) {\n            if (!userAgent) return undefined;\n\n            for (let index = 0; index < this.groups.length; index++) {\n                const group = this.groups[index];\n\n                if (group.userAgent.toLowerCase() === userAgent.toLowerCase()) {\n                    return group;\n                }\n            }\n\n            return undefined;\n        }\n\n        /**\n         * Calculate rule specificity score for path comparison\n         * @private\n         * @param {string} path - URL path pattern\n         * @return {number} - Specificity score (higher = more specific)\n         */\n        getRuleSpecificity(path) {\n            /** @type {number} */\n            let specificity = path.length;\n            if (path.indexOf('*') !== -1) specificity -= 0.5;\n            else if (path.slice(-1) === '$') specificity += 0.5;\n            return specificity;\n        }\n\n        /**\n         * Get groups applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Group[]} - Array of matching groups\n         */\n        getApplicableGroups(userAgent) {\n            /** @type {Group[]} */\n            const exactGroups = this.groups.filter(group => group.getName().toLowerCase() === userAgent.toLowerCase());\n            if (exactGroups.length > 0) return exactGroups;\n            return this.groups.filter(group => group.getName() === '*');\n        }\n\n        /**\n         * Get all rules applicable to specified user agent\n         * @private\n         * @param {string} userAgent - User agent to check\n         * @return {Rule[]} - Array of applicable rules\n         */\n        getApplicableRules(userAgent) {\n            /** @type {Rule[]} */\n            const rules = this.getApplicableGroups(userAgent);\n            return rules.reduce((acc, group) => acc.concat(group.getRules()), []);\n        }\n\n        /**\n         * Normalize URL path for comparison\n         * @private\n         * @param {string} url - URL or path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizeUrlPath(url) {\n            try {\n                return this.normalizePath(new URL(url).pathname);\n            } catch (error) {\n                return this.normalizePath(url);\n            }\n        }\n\n        /**\n         * Normalize path string for consistent comparisons\n         * @private\n         * @param {string} path - URL path to normalize\n         * @return {string} - Normalized path\n         */\n        normalizePath(path) {\n            /** @type {string} */\n            let decodedPath;\n\n            try {\n                decodedPath = decodeURIComponent(path);\n            } catch (error) {\n                decodedPath = path;\n            }\n\n            // Prepend forward slash if path not empty and does not start with\n            // forward slash\n            if (decodedPath && decodedPath[0] !== '/') return `/${decodedPath}`;\n\n            return decodedPath;\n        }\n\n        isValidTime(time) {\n            const hours = parseInt(time.substring(0, 2), 10);\n            const minutes = parseInt(time.substring(2, 4), 10);\n\n            // Validate hours and minutes\n            return hours >= 0 && hours <= 23 && minutes >= 0 && minutes <= 59;\n        }\n    }\n\n    /**\n     * Create a new robots.txt parser instance\n     * @param {string} content - Raw robots.txt content\n     * @return {RobotsTxtParser} - Configured parser instance\n     */\n    function robotstxt(content) {\n        return new RobotsTxtParser(content);\n    }\n\n    // Universal module exports\n    /* eslint-disable quote-props */\n    if (typeof exports !== 'undefined') {\n        exports.robotstxt = robotstxt;\n    }\n    if (typeof window !== 'undefined') {\n        window.robotstxt = robotstxt;\n        if (typeof define === 'function' && define.amd) {\n            define(() => ({ robotstxt }));\n        }\n    }\n    /* eslint-enable quote-props */\n}();\n"]}